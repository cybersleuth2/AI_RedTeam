ðŸš€ https://github.com/ottosulin/awesome-ai-security  
ðŸš€ https://github.com/Hannibal046/Awesome-LLM  
ðŸš€ https://github.com/greshake/llm-security    
ðŸš€ https://github.com/ScottLogic/prompt-injection  
ðŸš€ https://github.com/ReversecLabs/damn-vulnerable-llm-agent  
ðŸš€ https://github.com/mik0w/pallms  
ðŸš€ https://wiki.offsecml.com/Welcome+to+the+Offensive+ML+Playbook
ðŸš€ https://github.com/OWASP/www-project-top-10-for-large-language-model-applications/wiki/Vulnerable-LLM-Applications
ðŸš€ https://atlas.mitre.org/matrices/ATLAS/
ðŸš€ https://genai.owasp.org/  
ðŸš€ https://github.com/corca-ai/awesome-llm-security
ðŸš€ https://embracethered.com/blog/index.html
ðŸš€ https://promptairlines.com/
ðŸš€ https://platform.dreadnode.io/
ðŸš€ https://prompting.ai.immersivelabs.com/
ðŸš€ https://www.bugcrowd.com/wp-content/uploads/2024/04/Ultimate-Guide-AI-Security.pdf
ðŸš€ https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/red-teaming
ðŸš€ https://github.com/ScottLogic/prompt-injection
ðŸš€ https://lakera-marketing-public.s3.eu-west-1.amazonaws.com/Lakera%2BAI%2B-%2BReal%2BWorld%2BLLM%2BExploits%2B(Jan%2B2024)-min.pdf
ðŸš€ https://developer.nvidia.com/blog/nvidia-ai-red-team-an-introduction/
ðŸš€ https://systemweakness.com/large-language-model-llm-pen-testing-part-i-2ef96acb6763
ðŸš€ https://play.secdim.com/game/ai
ðŸš€ https://go.snyk.io/rs/677-THP-415/images/owasp-top-10-llm.pdf
ðŸš€ https://www.blazeinfosec.com/post/llm-pentest-agent-hacking/



https://www.hackerone.com/resources/e-book/the-ultimate-guide-to-managing-ethical-and-security-risks-in-ai
https://vickieli.medium.com/hacking-llms-with-prompt-injections-6a5ebffb182b  
https://aivillage.org/large%20language%20models/threat-modeling-llm/  
https://portswigger.net/web-security/llm-attacks  
https://gandalf.lakera.ai/  
https://www.ibm.com/think/topics/prompt-injection  
https://learnprompting.org/docs/prompt_hacking/injection  
https://llmsecurity.net/  
https://www.promptingguide.ai/risks/adversarial  
https://www.promptingguide.ai/research/rag  
https://www.cobalt.io/blog/prompt-injection-attacks  
https://www.bugcrowd.com/blog/ai-vulnerability-deep-dive-prompt-injection/  
https://www.unite.ai/prompt-hacking-and-misuse-of-llm/?trk=article-ssr-frontend-pulse_little-text-block    
https://simonwillison.net/2023/May/2/prompt-injection-explained/  

